# ğŸ—ï¸ Architecture Documentation

## System Overview

The Market Data Automation Tool follows a modular, pipeline-based architecture with clear separation of concerns.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Main Orchestrator                        â”‚
â”‚                      (main.py)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                       â”‚
         â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Configuration  â”‚                    â”‚   Logging System    â”‚
â”‚   (config.py)   â”‚                    â”‚   (Python logging)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ provides config to all modules
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Pipeline                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º 1. FETCH (fetch_data.py)
         â”‚   â””â”€â–º API Clients (Yahoo Finance, Alpha Vantage)
         â”‚       â””â”€â–º Retry Logic
         â”‚
         â”œâ”€â–º 2. TRANSFORM (transform_data.py)
         â”‚   â””â”€â–º Data Cleaning
         â”‚   â””â”€â–º Validation
         â”‚   â””â”€â–º Deduplication
         â”‚
         â”œâ”€â–º 3. STORE (storage.py)
         â”‚   â”œâ”€â–º SQLite Database
         â”‚   â””â”€â–º CSV Export
         â”‚
         â””â”€â–º 4. ALERT (alerts.py)
             â”œâ”€â–º Threshold Checking
             â”œâ”€â–º Console Notifications
             â””â”€â–º Email Notifications (optional)
```

## Module Architecture

### 1. Configuration Layer (`config.py`)

**Purpose:** Centralized configuration management

**Design Pattern:** Singleton-like class with class methods

**Responsibilities:**
- Load environment variables from `.env`
- Parse and validate configuration
- Provide configuration to all modules
- Ensure required directories exist

**Key Features:**
- Validation on import
- Type conversion (strings â†’ numbers, lists)
- Default values for optional settings
- Directory creation

```python
Config
â”œâ”€â”€ API Configuration
â”‚   â”œâ”€â”€ API_KEY
â”‚   â”œâ”€â”€ API_PROVIDER
â”‚   â””â”€â”€ API_RETRY_ATTEMPTS
â”œâ”€â”€ Symbols & Thresholds
â”‚   â”œâ”€â”€ SYMBOLS (list)
â”‚   â””â”€â”€ ALERT_THRESHOLDS (dict)
â”œâ”€â”€ Storage Paths
â”‚   â”œâ”€â”€ DATABASE_PATH
â”‚   â””â”€â”€ CSV_EXPORT_PATH
â””â”€â”€ Email Settings
    â”œâ”€â”€ ENABLE_EMAIL_ALERTS
    â””â”€â”€ SMTP_* credentials
```

### 2. Data Fetching Layer (`fetch_data.py`)

**Purpose:** Retrieve market data from external APIs

**Design Pattern:** Strategy pattern (multiple API providers)

**Class Structure:**
```python
MarketDataFetcher
â”œâ”€â”€ __init__(provider)
â”œâ”€â”€ fetch_quote(symbol) â†’ Dict
â”‚   â”œâ”€â”€ Retry logic (3 attempts)
â”‚   â””â”€â”€ Provider-specific methods:
â”‚       â”œâ”€â”€ _fetch_yfinance()
â”‚       â””â”€â”€ _fetch_alphavantage()
â””â”€â”€ fetch_multiple(symbols) â†’ List[Dict]
    â””â”€â”€ Rate limiting (0.5s between calls)
```

**Data Flow:**
```
User Request
    â†“
MarketDataFetcher.fetch_quote("AAPL")
    â†“
Retry Loop (max 3 attempts)
    â†“
Provider-Specific Fetch
    â”œâ”€â”€ yfinance: ticker.info
    â””â”€â”€ alphavantage: API call
    â†“
Standardized Output: {symbol, price, volume, timestamp, provider}
```

**Error Handling:**
- Network errors â†’ Retry with exponential backoff
- Invalid symbols â†’ Return None, log warning
- API errors â†’ Return None, log error
- Rate limit exceeded â†’ Sleep and retry

### 3. Data Transformation Layer (`transform_data.py`)

**Purpose:** Clean, validate, and standardize data

**Design Pattern:** Pipeline pattern

**Class Structure:**
```python
DataTransformer (Static Methods)
â”œâ”€â”€ clean_and_standardize(raw_data) â†’ DataFrame
â”‚   â”œâ”€â”€ Column normalization
â”‚   â”œâ”€â”€ Missing value handling
â”‚   â”œâ”€â”€ Type conversion
â”‚   â”œâ”€â”€ Timestamp normalization
â”‚   â””â”€â”€ Validation
â”œâ”€â”€ remove_duplicates(df, existing_df) â†’ DataFrame
â””â”€â”€ get_summary_statistics(df) â†’ Dict
```

**Transformation Pipeline:**
```
Raw Data List[Dict]
    â†“
1. Convert to DataFrame
    â†“
2. Standardize column names (lowercase)
    â†“
3. Handle missing values
   â”œâ”€â”€ Drop rows with NULL price
   â””â”€â”€ Fill volume=0 if missing
    â†“
4. Type conversion
   â”œâ”€â”€ price â†’ float64
   â””â”€â”€ volume â†’ int64
    â†“
5. Timestamp normalization
   â””â”€â”€ All timestamps â†’ UTC ISO format
    â†“
6. Add metadata
   â””â”€â”€ processed_at timestamp
    â†“
7. Validation
   â”œâ”€â”€ Remove invalid prices (â‰¤0)
   â””â”€â”€ Remove duplicates
    â†“
Clean DataFrame
```

**Data Quality Checks:**
- âœ… Required fields present (symbol, price, timestamp)
- âœ… Numeric consistency (price > 0, volume â‰¥ 0)
- âœ… No duplicates (symbol + timestamp unique)
- âœ… Timestamps in UTC
- âœ… Type correctness

### 4. Storage Layer (`storage.py`)

**Purpose:** Persist data in SQLite and CSV formats

**Design Pattern:** Repository pattern

**Database Schema:**
```sql
CREATE TABLE market_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    price REAL NOT NULL,
    volume INTEGER DEFAULT 0,
    timestamp TEXT NOT NULL,
    provider TEXT,
    processed_at TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol, timestamp)  -- Prevent duplicates
);

-- Indexes for performance
CREATE INDEX idx_symbol_timestamp ON market_data(symbol, timestamp);
CREATE INDEX idx_timestamp ON market_data(timestamp);
```

**Class Structure:**
```python
DataStorage
â”œâ”€â”€ __init__(db_path, csv_path)
â”‚   â””â”€â”€ _initialize_database()
â”œâ”€â”€ save_to_database(df) â†’ int
â”‚   â””â”€â”€ _save_with_ignore_duplicates()
â”œâ”€â”€ load_from_database(symbol, limit) â†’ DataFrame
â”œâ”€â”€ get_latest_prices() â†’ DataFrame
â”œâ”€â”€ export_to_csv(df, append)
â”œâ”€â”€ get_statistics() â†’ dict
â””â”€â”€ cleanup_old_data(days) â†’ int
```

**Storage Operations:**
```
DataFrame
    â†“
save_to_database()
    â”œâ”€â–º Try bulk insert
    â”‚   â””â”€â–º If duplicates detected â†’ Individual inserts
    â†“
SQLite Database
    â”œâ”€â–º UNIQUE constraint prevents duplicates
    â””â”€â–º Indexes ensure fast queries
    â†“
export_to_csv()
    â””â”€â–º CSV file (append mode)
```

**Query Patterns:**
- Get latest prices: `GROUP BY symbol, MAX(timestamp)`
- Historical data: `WHERE symbol = ? ORDER BY timestamp DESC`
- Statistics: Aggregations on symbol groups

### 5. Alert Layer (`alerts.py`)

**Purpose:** Monitor thresholds and send notifications

**Design Pattern:** Observer pattern

**Class Structure:**
```python
AlertManager
â”œâ”€â”€ __init__()
â”‚   â””â”€â”€ Load thresholds from Config
â”œâ”€â”€ check_thresholds(quote_data) â†’ List[Alert]
â”‚   â”œâ”€â”€ Check min threshold
â”‚   â””â”€â”€ Check max threshold
â”œâ”€â”€ check_multiple(quotes) â†’ List[Alert]
â”œâ”€â”€ send_alerts(alerts)
â”‚   â”œâ”€â”€ _send_console_alerts()
â”‚   â””â”€â”€ _send_email_alerts()
â”‚       â”œâ”€â”€ _create_text_email_body()
â”‚       â””â”€â”€ _create_html_email_body()
â””â”€â”€ get_threshold_summary() â†’ str
```

**Alert Decision Tree:**
```
Quote Data
    â†“
Symbol has thresholds?
    â”œâ”€â–º No â†’ Return []
    â””â”€â–º Yes
        â†“
    Price < min_threshold?
        â”œâ”€â–º Yes â†’ Create BELOW_MINIMUM alert
        â””â”€â–º No â†’ Continue
        â†“
    Price > max_threshold?
        â”œâ”€â–º Yes â†’ Create ABOVE_MAXIMUM alert
        â””â”€â–º No â†’ Continue
        â†“
    Return alerts[]
        â†“
    If alerts exist:
        â”œâ”€â–º Console output (always)
        â””â”€â–º Email (if enabled)
```

**Alert Data Structure:**
```python
{
    'symbol': 'AAPL',
    'current_price': 145.0,
    'threshold_type': 'BELOW_MINIMUM',
    'threshold_value': 150.0,
    'message': 'ğŸ”´ ALERT: AAPL fell below $150.00! Current: $145.00',
    'timestamp': '2024-02-10T10:00:00',
    'severity': 'HIGH'
}
```

### 6. Orchestration Layer (`main.py`)

**Purpose:** Coordinate all modules into a complete workflow

**Design Pattern:** Facade pattern

**Class Structure:**
```python
MarketDataAutomation
â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ Initialize storage
â”‚   â”œâ”€â”€ Initialize alert manager
â”‚   â””â”€â”€ Display configuration
â”œâ”€â”€ run() â†’ bool
â”‚   â”œâ”€â”€ Step 1: Fetch data
â”‚   â”œâ”€â”€ Step 2: Transform data
â”‚   â”œâ”€â”€ Step 3: Save data
â”‚   â”œâ”€â”€ Step 4: Check alerts
â”‚   â””â”€â”€ Step 5: Display summary
â”œâ”€â”€ _display_configuration()
â”œâ”€â”€ _display_summary()
â””â”€â”€ display_historical_data()
```

**Execution Flow:**
```
main()
    â†“
Config.validate()
    â†“
MarketDataAutomation()
    â†“
automation.run()
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Fetch Data     â”‚
â”‚  fetch_market_data()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Transform      â”‚
â”‚  transform_market_data()â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Save           â”‚
â”‚  save_data()            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Check Alerts   â”‚
â”‚  check_and_alert()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Summary        â”‚
â”‚  _display_summary()     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Models

### Quote Data Model
```python
{
    'symbol': str,          # Stock/crypto symbol
    'price': float,         # Current price
    'volume': int,          # Trading volume
    'timestamp': str,       # ISO format UTC timestamp
    'provider': str,        # Data source
    'processed_at': str     # Processing timestamp (added in transform)
}
```

### Alert Data Model
```python
{
    'symbol': str,
    'current_price': float,
    'threshold_type': str,  # 'BELOW_MINIMUM' or 'ABOVE_MAXIMUM'
    'threshold_value': float,
    'message': str,
    'timestamp': str,
    'severity': str         # 'HIGH', 'MEDIUM', 'LOW'
}
```

## Design Principles

### 1. Separation of Concerns
- Each module has a single, well-defined responsibility
- Clear interfaces between modules
- No cross-module dependencies (except config)

### 2. Dependency Injection
- Configuration injected via Config class
- Storage and alert managers can be instantiated independently
- Easy to mock for testing

### 3. Error Handling
- Graceful degradation (continue on single symbol failure)
- Comprehensive logging at all levels
- User-friendly error messages
- No silent failures

### 4. Extensibility
- Easy to add new API providers
- Easy to add new alert channels (Slack, Discord, etc.)
- Easy to add new storage backends
- Plugin-like architecture

### 5. Reliability
- Retry logic for network calls
- Database transactions
- Duplicate prevention
- Data validation

## Performance Considerations

### Database
- **Indexes** on frequently queried columns
- **UNIQUE constraint** prevents duplicate inserts
- **Batch inserts** when possible
- **Connection pooling** via context managers

### API Calls
- **Rate limiting** (0.5s between calls)
- **Retry with backoff** (2s delay)
- **Timeout** on HTTP requests (10s)
- **Concurrent calls** can be added via asyncio

### Memory
- **Streaming data** where possible
- **DataFrame operations** optimized
- **Logging rotation** to prevent log bloat
- **Database cleanup** function for old data

## Security Considerations

### Credentials
- âœ… Environment variables for secrets
- âœ… `.env` file not committed to git
- âœ… `.env.example` for documentation
- âŒ No hardcoded credentials

### Data
- âœ… Local storage (no cloud by default)
- âœ… No PII collected
- âœ… Email sent via TLS
- âœ… Database in user-controlled location

### Code
- âœ… Input validation on all user inputs
- âœ… SQL injection prevention (parameterized queries)
- âœ… Exception handling prevents crashes
- âœ… Logging doesn't expose secrets

## Testing Strategy

### Unit Tests
- DataTransformer logic
- Alert threshold logic
- Configuration parsing
- Data validation

### Integration Tests
- Full pipeline execution
- Database operations
- API calls (with mocking)

### Manual Testing
- Run with different configurations
- Verify outputs (DB, CSV, logs)
- Test alert triggers
- Test error scenarios

## Deployment Patterns

### Development
```
.env â†’ Use yfinance (no API key)
LOG_LEVEL â†’ DEBUG
Email â†’ Disabled
```

### Production
```
.env â†’ Use Alpha Vantage (with API key)
LOG_LEVEL â†’ INFO
Email â†’ Enabled
Cron â†’ Scheduled execution
```

### Monitoring
```
Logs â†’ logs/app.log
Cron logs â†’ logs/cron.log
Database size â†’ Monitor growth
Alert frequency â†’ Track in logs
```

## Future Enhancements

### Potential Additions
1. **Web Dashboard** - Visualize data with Flask/Dash
2. **Machine Learning** - Price predictions
3. **Technical Indicators** - RSI, MACD, etc.
4. **Backtesting** - Test strategies on historical data
5. **Multi-asset** - Support for forex, commodities
6. **Cloud Storage** - S3, Google Cloud Storage
7. **API Server** - RESTful API for data access
8. **Mobile App** - React Native companion app
9. **Slack Integration** - Alerts in Slack channels
10. **Real-time Streaming** - WebSocket for live data

---

**This architecture is designed to be:**
- ğŸ“¦ Modular
- ğŸ”’ Secure
- âš¡ Performant
- ğŸ§ª Testable
- ğŸ“ˆ Scalable
